#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø–µ—Ä–µ—Ö–≤–∞—Ç–∞ –∏ –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–∞—Ñ–∏–∫–∞ Google Gruyere.
–ü–æ–¥–¥–µ—Ä–∂–∫–∞ HTTP (–ø–æ—Ä—Ç 80/8080) –∏ HTTPS (–ø–æ—Ä—Ç 443) —Å —Ä–∞–∑–¥–µ–ª—å–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º.
"""
from scapy.all import sniff, wrpcap, IP, TCP, Raw
from scapy.layers.http import HTTPRequest, HTTPResponse
import gzip
import io
import argparse
from datetime import datetime
import logging
from typing import Optional, Dict, Any, List
from urllib.parse import urlparse

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('gruyere_sniffer.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class TrafficAnalyzer:
    """–ö–ª–∞—Å—Å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–µ—Ç–µ–≤–æ–≥–æ —Ç—Ä–∞—Ñ–∏–∫–∞"""
    
    def __init__(self):
        self.captured_packets: List = []
        self.http_requests: List[Dict] = []
        self.http_responses: List[Dict] = []
        self.https_packets: List = []  # HTTPS —Ç—Ä–∞—Ñ–∏–∫ (—à–∏—Ñ—Ä–æ–≤–∞–Ω–Ω—ã–π)
        
    def extract_http_headers(self, raw_data: bytes) -> Dict[str, str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç HTTP –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∏–∑ —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        headers = {}
        try:
            # –†–∞–∑–¥–µ–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∏ —Ç–µ–ª–æ
            parts = raw_data.split(b'\r\n\r\n', 1)
            if len(parts) > 0:
                header_lines = parts[0].decode('utf-8', errors='ignore').split('\r\n')
                for line in header_lines[1:]:  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É
                    if ': ' in line:
                        key, value = line.split(': ', 1)
                        headers[key.strip()] = value.strip()
        except Exception as e:
            logger.debug(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤: {e}")
        return headers
    
    def is_gzip_encoded(self, headers: Dict[str, str]) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å–∂–∞—Ç–æ –ª–∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ gzip"""
        content_encoding = headers.get('Content-Encoding', '').lower()
        return 'gzip' in content_encoding
    
    def decode_gzip_content(self, content: bytes) -> str:
        """–î–µ–∫–æ–¥–∏—Ä—É–µ—Ç gzip —Å–∂–∞—Ç–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ"""
        try:
            with gzip.GzipFile(fileobj=io.BytesIO(content)) as f:
                return f.read().decode('utf-8', errors='ignore')
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è gzip: {e}")
            return content.decode('utf-8', errors='ignore')
    
    def analyze_http_packet(self, packet) -> Optional[Dict[str, Any]]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç HTTP –ø–∞–∫–µ—Ç –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –ø–æ–ª–µ–∑–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é"""
        try:
            result = {
                'timestamp': datetime.now().isoformat(),
                'src_ip': packet[IP].src if IP in packet else 'Unknown',
                'dst_ip': packet[IP].dst if IP in packet else 'Unknown',
                'src_port': packet[TCP].sport if TCP in packet else 0,
                'dst_port': packet[TCP].dport if TCP in packet else 0,
            }
            
            if packet.haslayer(HTTPRequest):
                http_layer = packet[HTTPRequest]
                result['type'] = 'REQUEST'
                result['method'] = http_layer.Method.decode('utf-8', errors='ignore') if http_layer.Method else 'UNKNOWN'
                result['path'] = http_layer.Path.decode('utf-8', errors='ignore') if http_layer.Path else '/'
                result['host'] = http_layer.Host.decode('utf-8', errors='ignore') if http_layer.Host else ''
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–ª–æ –∑–∞–ø—Ä–æ—Å–∞
                if Raw in packet:
                    raw_data = packet[Raw].load
                    headers = self.extract_http_headers(raw_data)
                    result['headers'] = headers
                    
                    # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å —Ç–µ–ª–æ
                    parts = raw_data.split(b'\r\n\r\n', 1)
                    if len(parts) > 1 and parts[1]:
                        result['body'] = parts[1].decode('utf-8', errors='ignore')
                    else:
                        result['body'] = ''
                
                self.http_requests.append(result)
                
            elif packet.haslayer(HTTPResponse):
                http_layer = packet[HTTPResponse]
                result['type'] = 'RESPONSE'
                result['status_code'] = http_layer.Status_Code.decode('utf-8', errors='ignore') if http_layer.Status_Code else '000'
                result['reason'] = http_layer.Reason_Phrase.decode('utf-8', errors='ignore') if http_layer.Reason_Phrase else ''
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–µ–ª–æ –æ—Ç–≤–µ—Ç–∞
                if Raw in packet:
                    raw_data = packet[Raw].load
                    headers = self.extract_http_headers(raw_data)
                    result['headers'] = headers
                    
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–ª–æ
                    parts = raw_data.split(b'\r\n\r\n', 1)
                    if len(parts) > 1 and parts[1]:
                        body_content = parts[1]
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–∂–∞—Ç–∏–µ
                        if self.is_gzip_encoded(headers):
                            result['body'] = self.decode_gzip_content(body_content)
                            result['compression'] = 'gzip'
                        else:
                            result['body'] = body_content.decode('utf-8', errors='ignore')
                            result['compression'] = 'none'
                    else:
                        result['body'] = ''
                        result['compression'] = 'none'
                
                self.http_responses.append(result)
            
            return result
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ HTTP –ø–∞–∫–µ—Ç–∞: {e}")
            return None
    
    def packet_callback(self, packet):
        """Callback —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–∞–∂–¥–æ–≥–æ –ø–∞–∫–µ—Ç–∞"""
        try:
            self.captured_packets.append(packet)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Ä—Ç –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–∞ —Ç—Ä–∞—Ñ–∏–∫–∞
            if TCP in packet:
                dst_port = packet[TCP].dport
                src_port = packet[TCP].sport
                
                # HTTPS —Ç—Ä–∞—Ñ–∏–∫ (–ø–æ—Ä—Ç 443)
                if dst_port == 443 or src_port == 443:
                    self.https_packets.append(packet)
                    logger.debug(f"HTTPS –ø–∞–∫–µ—Ç: {packet[IP].src}:{src_port} -> {packet[IP].dst}:{dst_port}")
                    return None
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º HTTP —Ç—Ä–∞—Ñ–∏–∫
            if packet.haslayer(HTTPRequest) or packet.haslayer(HTTPResponse):
                analysis = self.analyze_http_packet(packet)
                
                if analysis:
                    # –õ–æ–≥–∏—Ä—É–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
                    if analysis['type'] == 'REQUEST':
                        logger.info(f"HTTP Request: {analysis['method']} {analysis['path']}")
                        print(f"\n[REQUEST] {analysis['method']} {analysis['path']}")
                        print(f"  Host: {analysis['host']}")
                        print(f"  From: {analysis['src_ip']}:{analysis['src_port']}")
                    else:
                        logger.info(f"HTTP Response: {analysis['status_code']} {analysis['reason']}")
                        print(f"\n[RESPONSE] {analysis['status_code']} {analysis['reason']}")
                        print(f"  To: {analysis['dst_ip']}:{analysis['dst_port']}")
                        
                        # –í—ã–≤–æ–¥–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–∂–∞—Ç–∏–∏
                        if analysis.get('compression') == 'gzip':
                            print(f"  Compression: gzip")
                        
                        # –í—ã–≤–æ–¥–∏–º –ø–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤ —Ç–µ–ª–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
                        if 'body' in analysis and analysis['body']:
                            body_preview = analysis['body'][:200]
                            print(f"  Body preview: {body_preview}")
                    
                    return analysis
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–∞–∫–µ—Ç–∞: {e}")
            return None
    
    def save_results(self, pcap_filename: str):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞"""
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–µ—Å—å —Ç—Ä–∞—Ñ–∏–∫ –≤ pcap
        if self.captured_packets:
            logger.info(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ {len(self.captured_packets)} –ø–∞–∫–µ—Ç–æ–≤ –≤ {pcap_filename}")
            wrpcap(pcap_filename, self.captured_packets)
            print(f"‚úÖ –¢—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {pcap_filename}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑ –≤ —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª
        with open('traffic_analysis.txt', 'w', encoding='utf-8') as f:
            f.write("–ê–ù–ê–õ–ò–ó –¢–†–ê–§–ò–ö–ê GOOGLE GRUYERE\n")
            f.write("="*60 + "\n\n")
            f.write(f"–î–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞: {datetime.now().strftime('%d.%m.%Y %H:%M:%S')}\n")
            f.write(f"–í—Å–µ–≥–æ –ø–∞–∫–µ—Ç–æ–≤: {len(self.captured_packets)}\n")
            f.write(f"HTTP –∑–∞–ø—Ä–æ—Å–æ–≤: {len(self.http_requests)}\n")
            f.write(f"HTTP –æ—Ç–≤–µ—Ç–æ–≤: {len(self.http_responses)}\n")
            f.write(f"HTTPS –ø–∞–∫–µ—Ç–æ–≤ (—à–∏—Ñ—Ä–æ–≤–∞–Ω–Ω—ã—Ö): {len(self.https_packets)}\n")
            
            if self.https_packets:
                f.write("\n‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –û–±–Ω–∞—Ä—É–∂–µ–Ω HTTPS —Ç—Ä–∞—Ñ–∏–∫ (–ø–æ—Ä—Ç 443)\n")
                f.write("   –°–æ–¥–µ—Ä–∂–∏–º–æ–µ HTTPS –ø–∞–∫–µ—Ç–æ–≤ –∑–∞—à–∏—Ñ—Ä–æ–≤–∞–Ω–æ –∏ –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–æ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.\n")
                f.write("   –î–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ª–æ–∫–∞–ª—å–Ω—ã–π Google Gruyere –Ω–∞ –ø–æ—Ä—Ç—É 8080.\n")
            
            f.write("\n" + "="*50 + "\n")
            
            for req in self.http_requests:
                f.write(f"\n[REQUEST] {req['method']} {req['path']}\n")
                f.write(f"Host: {req['host']}\n")
                f.write(f"From: {req['src_ip']}:{req['src_port']}\n")
                if 'body' in req and req['body']:
                    f.write(f"Body: {req['body'][:500]}\n")
            
            for resp in self.http_responses:
                f.write(f"\n[RESPONSE] {resp['status_code']} {resp['reason']}\n")
                f.write(f"To: {resp['dst_ip']}:{resp['dst_port']}\n")
                if resp.get('compression') == 'gzip':
                    f.write(f"Compression: gzip\n")
                if 'body' in resp and resp['body']:
                    # –ò—â–µ–º –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ XSS —É—è–∑–≤–∏–º–æ—Å—Ç–∏
                    body_lower = resp['body'].lower()
                    if '<script>' in body_lower or 'onerror=' in body_lower:
                        f.write("‚ö†Ô∏è –í–û–ó–ú–û–ñ–ù–ê–Ø XSS –£–Ø–ó–í–ò–ú–û–°–¢–¨ –í –¢–ï–õ–ï –û–¢–í–ï–¢–ê!\n")
                    f.write(f"Body preview: {resp['body'][:500]}\n")
        
        print(f"‚úÖ –ê–Ω–∞–ª–∏–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ traffic_analysis.txt")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        print(f"\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
        print(f"  –í—Å–µ–≥–æ –ø–∞–∫–µ—Ç–æ–≤: {len(self.captured_packets)}")
        print(f"  HTTP –∑–∞–ø—Ä–æ—Å–æ–≤: {len(self.http_requests)}")
        print(f"  HTTP –æ—Ç–≤–µ—Ç–æ–≤: {len(self.http_responses)}")
        print(f"  HTTPS –ø–∞–∫–µ—Ç–æ–≤: {len(self.https_packets)}")
        
        if self.https_packets:
            print(f"\n‚ö†Ô∏è –û–ë–ù–ê–†–£–ñ–ï–ù HTTPS –¢–†–ê–§–ò–ö!")
            print("   –°–æ–¥–µ—Ä–∂–∏–º–æ–µ –∑–∞—à–∏—Ñ—Ä–æ–≤–∞–Ω–æ. –î–ª—è –∞–Ω–∞–ª–∏–∑–∞ XSS –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ:")
            print("   1. –õ–æ–∫–∞–ª—å–Ω—ã–π Google Gruyere (python3 gruyere.py)")
            print("   2. MITM-–ø—Ä–æ–∫—Å–∏ –¥–ª—è —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∏ HTTPS")

def validate_url(url: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å URL"""
    try:
        result = urlparse(url)
        return all([result.scheme, result.netloc])
    except:
        return False

def main():
    parser = argparse.ArgumentParser(description='–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Ç—Ä–∞—Ñ–∏–∫–∞ Google Gruyere')
    parser.add_argument('--interface', default=None, help='–°–µ—Ç–µ–≤–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏—è')
    parser.add_argument('--output', default='gruyere_traffic.pcap', help='–ò–º—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ .pcap —Ñ–∞–π–ª–∞')
    parser.add_argument('--count', type=int, default=0, help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞–∫–µ—Ç–æ–≤ –¥–ª—è –∑–∞—Ö–≤–∞—Ç–∞ (0 = –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ)')
    parser.add_argument('--timeout', type=int, default=300, help='–¢–∞–π–º–∞—É—Ç –∑–∞—Ö–≤–∞—Ç–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö')
    parser.add_argument('--port', type=int, default=8080, help='–ü–æ—Ä—Ç –¥–ª—è –∑–∞—Ö–≤–∞—Ç–∞ HTTP —Ç—Ä–∞—Ñ–∏–∫–∞')
    
    args = parser.parse_args()
    
    print("=" * 70)
    print("–ê–ù–ê–õ–ò–ó–ê–¢–û–† –¢–†–ê–§–ò–ö–ê GOOGLE GRUYERE")
    print("=" * 70)
    print(f"–î–∞—Ç–∞ –∑–∞–ø—É—Å–∫–∞: {datetime.now().strftime('%d.%m.%Y %H:%M:%S')}")
    print("\n–í–ê–ñ–ù–û: –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ª–æ–∫–∞–ª—å–Ω—ã–π –∑–∞–ø—É—Å–∫ Google Gruyere:")
    print("  $ git clone https://github.com/google/gruyere")
    print("  $ cd gruyere && python3 gruyere.py")
    print("\n–û–±–ª–∞—á–Ω–∞—è –≤–µ—Ä—Å–∏—è (HTTPS) —Å–ª–æ–∂–Ω–µ–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞!")
    print("=" * 70 + "\n")
    
    analyzer = TrafficAnalyzer()
    
    try:
        # –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π —Ñ–∏–ª—å—Ç—Ä –¥–ª—è –∑–∞—Ö–≤–∞—Ç–∞ HTTP/HTTPS —Ç—Ä–∞—Ñ–∏–∫–∞
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–æ—Ä—Ç –∏–ª–∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –ø–æ—Ä—Ç—ã HTTP/HTTPS
        if args.port == 8080:
            filter_str = f"tcp port {args.port} or tcp port 80 or tcp port 443"
        else:
            filter_str = f"tcp port {args.port}"
        
        logger.info(f"–ó–∞–ø—É—Å–∫ —Å–Ω–∏—Ñ—Ñ–µ—Ä–∞ —Å —Ñ–∏–ª—å—Ç—Ä–æ–º: {filter_str}")
        print(f"–ó–∞—Ö–≤–∞—Ç —Ç—Ä–∞—Ñ–∏–∫–∞ –Ω–∞ –ø–æ—Ä—Ç–∞—Ö: {filter_str}")
        print("–ù–∞–∂–º–∏—Ç–µ Ctrl+C –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –∑–∞—Ö–≤–∞—Ç–∞...\n")
        
        sniff(
            prn=analyzer.packet_callback,
            filter=filter_str,
            store=False,
            count=args.count,
            timeout=args.timeout,
            iface=args.interface
        )
        
    except KeyboardInterrupt:
        print("\n\n–ó–∞—Ö–≤–∞—Ç —Ç—Ä–∞—Ñ–∏–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        logger.info("–ó–∞—Ö–≤–∞—Ç —Ç—Ä–∞—Ñ–∏–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ –∫–æ–º–∞–Ω–¥–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")
    
    except PermissionError:
        print("\n‚ùå –û–®–ò–ë–ö–ê: –¢—Ä–µ–±—É—é—Ç—Å—è –ø—Ä–∞–≤–∞ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞!")
        print("–ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–∫—Ä–∏–ø—Ç —Å sudo: sudo python3 gruyere_sniffer.py")
        logger.error("PermissionError: –¢—Ä–µ–±—É—é—Ç—Å—è –ø—Ä–∞–≤–∞ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞")
        return
    
    except Exception as e:
        print(f"\n‚ùå –û–®–ò–ë–ö–ê: {e}")
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞—Ö–≤–∞—Ç–µ —Ç—Ä–∞—Ñ–∏–∫–∞: {e}")
    
    finally:
        analyzer.save_results(args.output)

if __name__ == "__main__":
    main()
